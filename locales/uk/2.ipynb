{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f0925a6-9f2a-4d4a-bd48-3628d4f2207f",
   "metadata": {},
   "source": [
    "# 2 Training the model\n",
    "## 2.1 Load the Training data\n",
    "Before starting, we will load a list of lemmas from the previous part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a3a299a-06b2-4e35-bb0b-b1275014e319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269430 items loaded from lemmae.json\n"
     ]
    }
   ],
   "source": [
    "# Dump the lemmas to a json file\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Change this variable to load another list of lemmas\n",
    "locale = \"uk-UA\"\n",
    "\n",
    "# Define the file path\n",
    "file_path = f\"lemmae.json\"\n",
    "\n",
    "# Write the lemmas list to the JSON file\n",
    "try:\n",
    "    with open(file_path) as f:\n",
    "        content = f.read()\n",
    "        if not content.strip():\n",
    "            raise ValueError(\"The JSON file is empty.\")\n",
    "        lemmas = json.loads(content)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {file_path}\")\n",
    "    lemmas = []\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    lemmas = []\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error: Invalid JSON content in {file_path}\")\n",
    "    lemmas = []\n",
    "\n",
    "print(f\"{len(lemmas)} items loaded from {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8665a5c7-1386-4e65-b2cb-993957adbf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy<2 in /Users/alan/miniconda3/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: torch in /Users/alan/miniconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /Users/alan/miniconda3/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/alan/miniconda3/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/alan/miniconda3/lib/python3.12/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/alan/miniconda3/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/alan/miniconda3/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/alan/miniconda3/lib/python3.12/site-packages (from torch) (2025.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/alan/miniconda3/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/alan/miniconda3/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# ensure you have the necessary library\n",
    "%pip install 'numpy<2', torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12590940-74f8-43f3-ba15-b87abd287b36",
   "metadata": {},
   "source": [
    "## 2 Prepare the training sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a092511-259c-4e49-b21e-5c291c4533bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CharDataset(Dataset):\n",
    "    def __init__(self, sequences, vocab, separator_tag=None):\n",
    "        self.sequences = sequences\n",
    "        self.vocab = vocab\n",
    "        self.char_to_idx = {char: idx for idx, char in enumerate(vocab)}\n",
    "        self.idx_to_char = {idx: char for idx, char in enumerate(vocab)}\n",
    "        if separator_tag != None:\n",
    "            self.sep_tag = separator_tag\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        input_seq = [self.char_to_idx[char] for char in sequence[:-1]]\n",
    "        target_seq = [self.char_to_idx[char] for char in sequence[1:]]\n",
    "        return torch.tensor(input_seq), torch.tensor(target_seq)\n",
    "\n",
    "# In this case \"vocab\" is literally the latin alphabet\n",
    "vocab = sorted(set(\"\".join(lemmas)))\n",
    "dataset = CharDataset(lemmas, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614be4a9-a8be-4b05-9486-43baca068484",
   "metadata": {},
   "source": [
    "This loaded the lemmas in a dataset in a format that torch can understand. Each word is turned in a pair of sequences, an input (missing the last character) and a target (missing the first character). In this case, because the input sequences start with an added \"start of sequence\" special token, the target sequence is the full word. In plain English, this means that we also want our model to learn what is the most likely first letter of a word, not only the next most likely character based on the beginning of the sequence.\n",
    "\n",
    "All the characters are converted to numbers, each being the index of the input neuron that will be activated during the training. The system has as many inputs neurons, or input dimensions, as there are items in the vocabulary (by vocabulary, we mean alphabet). This is a reasonable number that allows the model to train on any computer, but imagine the size of a model when the vocabulary contains hundred of thousands of words (from different languages), and that each one needs its own input neuron...\n",
    "\n",
    "Run the following block to see how your data will be processed by the neural network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9733a619-5c39-435f-a42b-5d47fa048186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== біоцид == \n",
      "becomes the sequences:\n",
      "tensor([ 3, 32, 16, 24, 10]) (input)\n",
      "and tensor([32, 16, 24, 10,  6]) (target)\n"
     ]
    }
   ],
   "source": [
    "from random import randrange\n",
    "n = randrange(len(lemmas))\n",
    "\n",
    "print(f\"== {lemmas[n]} == \\nbecomes the sequences:\\n{dataset[n][0]} (input)\\nand {dataset[n][1]} (target)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74849eb5-b20d-47f6-bd66-fe0a90e815db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaders ready:\n",
      " <torch.utils.data.dataloader.DataLoader object at 0x11d21bef0> \n",
      " <torch.utils.data.dataloader.DataLoader object at 0x128e81490>\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(lemmas)\n",
    "percent_len = len(lemmas)//1000\n",
    "sequences = [\"\\n\" + \"\\n\".join(lemmas[(n-1)*percent_len:n*percent_len])+ \"\\n\" for n in range(1, 1001)]\n",
    "seq_training = sequences[:850]\n",
    "seq_validating = sequences[850:]\n",
    "vocab = sorted(set(\"\".join(sequences)))\n",
    "dataset = CharDataset(seq_training, vocab, \"\\n\")\n",
    "dataset_eval = CharDataset(seq_validating, vocab, \"\\n\")\n",
    "dataloader = DataLoader(dataset, shuffle=True)\n",
    "dataloader_eval = DataLoader(dataset_eval, shuffle=True)\n",
    "print(\"Data loaders ready:\\n\", dataloader, \"\\n\", dataloader_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579308aa-5420-49dd-8bd5-e61a641d300e",
   "metadata": {},
   "source": [
    "## 2.2 Defining the Model\n",
    "\n",
    "In this part we design our network. We first initialize a PyTorch [module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module) by defining the different parts of the network: an embedding layer to turn each character in a 16 dimensional vector (an array of 16 numbers), one LSTM cell (`layers_number`) that will do the actual pattern recognition and prediction work and the linear fully connected (self.fc) layer converts these predictions in a simple discrete value, i.e. the index of the next character.\n",
    "\n",
    "The forward function defines the order in which the input data will go through the network. It outputs the prediction and the updated hidden layer of the LSTM cells (these hidden states are updated even during the forward pass). And finally we have a function initializing the these hidden states with empty tensors of the good shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e30cdb7-5fb6-4e0c-956a-906ac4b98867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready! Total number of parameters: 69108\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, embedding_dim=4, hidden_dim=16, layers_number=1, char_to_idx={}, idx_to_char={}):\n",
    "        super().__init__()\n",
    "        vocab_size = len(char_to_idx.keys())\n",
    "        self.char_to_idx = char_to_idx\n",
    "        self.idx_to_char = idx_to_char\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, layers_number, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    # The forward function is the one getting called everytime\n",
    "    # the model created by an instance of this class is called\n",
    "    # model(x, hidden) == model.forward(x, hidden)\n",
    "    def forward(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size=1):\n",
    "        return (torch.zeros(layers_number, batch_size , hidden_dim),\n",
    "                torch.zeros(layers_number, batch_size , hidden_dim))\n",
    "\n",
    "# Example usage\n",
    "embedding_dim = 12\n",
    "hidden_dim = 120\n",
    "layers_number = 1\n",
    "char_to_idx = dataset.char_to_idx\n",
    "idx_to_char = dataset.idx_to_char\n",
    "\n",
    "model = LSTMModel(embedding_dim, hidden_dim, layers_number, char_to_idx, idx_to_char)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Model ready! Total number of parameters: {total_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea96458c-be6a-4b0e-a152-caf24655d730",
   "metadata": {},
   "source": [
    "# 2.3 Training\n",
    "After defining a couple of hyperparameters, we are ready to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43340eb4-bfe3-4e7f-bfe8-fca1e717dbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                    | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaders ready:\n",
      " <torch.utils.data.dataloader.DataLoader object at 0x1651cc1a0> \n",
      " <torch.utils.data.dataloader.DataLoader object at 0x128f41e50>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██▊                         | 1/10 [00:17<02:38, 17.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 1.7150, Validation Loss: 1.6986\n",
      "Data loaders ready:\n",
      " <torch.utils.data.dataloader.DataLoader object at 0x16539c110> \n",
      " <torch.utils.data.dataloader.DataLoader object at 0x16539e750>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████▌                      | 2/10 [00:34<02:17, 17.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Training Loss: 1.7095, Validation Loss: 1.6816\n",
      "Data loaders ready:\n",
      " <torch.utils.data.dataloader.DataLoader object at 0x16539cb60> \n",
      " <torch.utils.data.dataloader.DataLoader object at 0x128f41e50>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████▍                   | 3/10 [00:51<01:58, 16.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Training Loss: 1.7093, Validation Loss: 1.7165\n",
      "Data loaders ready:\n",
      " <torch.utils.data.dataloader.DataLoader object at 0x16539c920> \n",
      " <torch.utils.data.dataloader.DataLoader object at 0x16539cb60>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████▏                | 4/10 [01:07<01:41, 16.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Training Loss: 1.7046, Validation Loss: 1.6819\n",
      "Data loaders ready:\n",
      " <torch.utils.data.dataloader.DataLoader object at 0x16539d490> \n",
      " <torch.utils.data.dataloader.DataLoader object at 0x128f41e50>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████              | 5/10 [01:25<01:25, 17.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Training Loss: 1.7011, Validation Loss: 1.7088\n",
      "Data loaders ready:\n",
      " <torch.utils.data.dataloader.DataLoader object at 0x16539e750> \n",
      " <torch.utils.data.dataloader.DataLoader object at 0x16539d490>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████▊           | 6/10 [01:43<01:09, 17.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Training Loss: 1.6982, Validation Loss: 1.7110\n",
      "Data loaders ready:\n",
      " <torch.utils.data.dataloader.DataLoader object at 0x16539ec90> \n",
      " <torch.utils.data.dataloader.DataLoader object at 0x16539e750>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████████████████▌        | 7/10 [02:01<00:52, 17.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Training Loss: 1.7015, Validation Loss: 1.7377\n",
      "Data loaders ready:\n",
      " <torch.utils.data.dataloader.DataLoader object at 0x16539c410> \n",
      " <torch.utils.data.dataloader.DataLoader object at 0x16539ec90>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████▍     | 8/10 [02:18<00:35, 17.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Training Loss: 1.6953, Validation Loss: 1.6809\n",
      "Data loaders ready:\n",
      " <torch.utils.data.dataloader.DataLoader object at 0x16539c620> \n",
      " <torch.utils.data.dataloader.DataLoader object at 0x128f41e50>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████▏  | 9/10 [02:36<00:17, 17.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Training Loss: 1.6931, Validation Loss: 1.6802\n",
      "Data loaders ready:\n",
      " <torch.utils.data.dataloader.DataLoader object at 0x1651cc8c0> \n",
      " <torch.utils.data.dataloader.DataLoader object at 0x16539c620>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████| 10/10 [02:55<00:00, 17.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Training Loss: 1.6922, Validation Loss: 1.7450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 10\n",
    "learning_rate = 0.005\n",
    "vocab_size = len(char_to_idx)\n",
    "\n",
    "# Loss function and optimizer\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    \n",
    "    random.shuffle(lemmas)\n",
    "    percent_len = len(lemmas)//1000\n",
    "    sequences = [\"\\n\" + \"\\n\".join(lemmas[(n-1)*percent_len:n*percent_len])+ \"\\n\" for n in range(1, 1001)]\n",
    "    seq_training = sequences[:850]\n",
    "    seq_validating = sequences[850:]\n",
    "    vocab = sorted(set(\"\".join(sequences)))\n",
    "    dataset = CharDataset(seq_training, vocab, \"\\n\")\n",
    "    dataset_eval = CharDataset(seq_validating, vocab, \"\\n\")\n",
    "    dataloader = DataLoader(dataset, shuffle=True)\n",
    "    dataloader_eval = DataLoader(dataset_eval, shuffle=True)\n",
    "    \n",
    "    # first, train the model\n",
    "    model.train()\n",
    "    hidden = model.init_hidden()\n",
    "    training_loss = 0\n",
    "    for inputs, targets in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs, hidden = model.forward(inputs, hidden)\n",
    "        loss = cross_entropy(outputs.view(-1, vocab_size), targets.squeeze(0))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        training_loss = loss.item()\n",
    "        hidden = (hidden[0].detach(), hidden[1].detach())\n",
    "        \n",
    "    # second, evaluate the model to avoid overfitting\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    for inputs, targets in dataloader_eval:\n",
    "        hidden = model.init_hidden()\n",
    "\n",
    "        # forward pass\n",
    "        outputs, hidden = model.forward(inputs, hidden)\n",
    "        loss = cross_entropy(outputs.view(-1, vocab_size), targets.squeeze(0))\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss_eval = total_loss / len(dataloader_eval)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {avg_loss_eval:.4f}, Validation Loss: {training_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b7b99f-1504-437d-b81d-0f7446d9d985",
   "metadata": {},
   "source": [
    "## 2.4 Generating the Pseudo-words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3bba2876-5db6-493f-847d-0670365fe84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 words so far\n",
      "абизація\n",
      "авомозонний\n",
      "авсинювання\n",
      "автинобірний\n",
      "автоконфралістот\n",
      "автомасенерал\n",
      "автоматротний\n",
      "автопропутатичний\n",
      "автосекративний\n",
      "автоуправлений\n",
      "щоякнайлінія\n",
      "щоякнайнерезнативніший\n",
      "щоякнайнетілкніший\n",
      "щоякнайповнопривасніший\n",
      "щоякнайсишиніше\n",
      "щоякнайсмавчий\n",
      "щоякнайсмолодіше\n",
      "щоякнайсонфілізуваний\n",
      "щоякнайхиганіший\n",
      "щоякнайхорчіший\n",
      "щіління\n",
      "юватися\n",
      "юдцевий\n",
      "явкнарад\n",
      "якнай\n",
      "якнайзахаткованіший\n",
      "якнаймахнішніший\n",
      "якнайнавправний\n",
      "якнайнедостедерний\n",
      "якнайнезволошитись\n",
      "якнайнеслабльніший\n",
      "якнайнесмонованіший\n",
      "якнайпатарний\n",
      "якнайпостатніше\n",
      "якнайручнаніший\n",
      "якнайсидовіший\n",
      "якнайтаракініший\n",
      "якнайчка\n",
      "яновик\n",
      "ярганника\n",
      "яскрадитися\n",
      "ятківський\n",
      "інбам-нанком\n",
      "індефоксація\n",
      "індіабузи\n",
      "інтербожа\n",
      "іонорієнтація\n",
      "ісклісний\n",
      "іскцеатовий\n",
      "їдерня\n",
      "12.174\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "import torch.nn.functional as F\n",
    "from spylls.hunspell import Dictionary\n",
    "import sys\n",
    "dictionary = Dictionary.from_files(f\"hunspell/{locale}\")\n",
    "\n",
    "\n",
    "def generate_pseudoword(model, length=15, temperature=0.9):\n",
    "    model.eval()\n",
    "    hidden = model.init_hidden(1)\n",
    "    start_seq = [0]\n",
    "    inputs = torch.tensor(start_seq).unsqueeze(0)  # Shape: (1, seq_len)\n",
    "    generated_seq = []\n",
    "    words_generated = set([])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        while len(words_generated) < length:\n",
    "            outputs, hidden = model(inputs, hidden)\n",
    "\n",
    "            # outputs shape: (1, seq_len, vocab_size)\n",
    "            # We need the last time step's output for the next prediction\n",
    "            last_output = outputs[:, -1]  # Shape: (1, vocab_size)\n",
    "\n",
    "            # Apply temperature scaling\n",
    "            last_output = last_output / temperature\n",
    "            probs = F.softmax(last_output, dim=-1).squeeze(0)  # the multinomial accepts only one order tensors\n",
    "\n",
    "            # Ensure all the probabilities are valid\n",
    "            if torch.isnan(probs).any() or torch.isinf(probs).any() or (probs < 0).any():\n",
    "                print(\"Invalid probabilities detected. Resetting to uniform distribution.\")\n",
    "                probs = torch.ones_like(probs) / probs.size(0)\n",
    "\n",
    "            # Sample the next character\n",
    "            predicted_idx = torch.multinomial(probs, 1).item()\n",
    "            generated_seq.append(predicted_idx)\n",
    "            inputs = torch.tensor([[predicted_idx]])  # Shape: (1, 1)\n",
    "\n",
    "            if vocab[predicted_idx] == \"\\n\":\n",
    "                new_word = ''.join([vocab[i] for i in generated_seq[:-1]])\n",
    "                generated_seq = []\n",
    "                if not dictionary.lookup(new_word.capitalize()) and new_word not in lemmas:\n",
    "                    words_generated.add(new_word)\n",
    "                sys.stdout.write(f\"\\r{len(words_generated)} words so far\")\n",
    "\n",
    "    return list(sorted(words_generated))\n",
    "\n",
    "# Example usage\n",
    "generated_pseudoword = generate_pseudoword(model, 1000)\n",
    "print()\n",
    "print(\"\\n\".join(generated_pseudoword[:10]))\n",
    "print(\"\\n\".join(generated_pseudoword[-40:]))\n",
    "print(len(\"\\n\".join(generated_pseudoword))/len(generated_pseudoword))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4793c5a7-b546-4795-930e-1f995dc8d051",
   "metadata": {},
   "source": [
    "# 5 Saving and loading our results\n",
    "\n",
    "If you are happy with the results, like the loss, especially against the validation set, and the words generated, you can run the following block to save the model's weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a96cd4fa-f64a-42e5-99fe-3a9bf19d2bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model you've trained so far\n",
    "torch.save(model, f'lstm_model-{locale}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2630750-87de-46cc-a530-96e59f2d4d81",
   "metadata": {},
   "source": [
    "Or use this block to load a previously saved model to generate more non-words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c34dd0-78bd-41c7-9111-30da7d0add49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate words from the the last version of the model you saved\n",
    "model = torch.load(f'locales/{locale}/lstm_model-{locale}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2be5996-610d-4618-a0b9-44a4e92a2f68",
   "metadata": {},
   "source": [
    "We can now generate our pseudo-lexicon. To find it, look out for the pseudo-lemmas.json file in the dictionary folder of your source dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d29b0c45-fad1-4158-bb83-0f473d321de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 words so far\n",
      "50000 pseudo words successfully generated and loaded in 15:24.290\n"
     ]
    }
   ],
   "source": [
    "# Dump the lemmas to a json file\n",
    "import json\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Define the output file path\n",
    "output_file_path = f\"pseudo-lemmae.json\"\n",
    "\n",
    "generated_pseudoword = generate_pseudoword(model, 50000)\n",
    "\n",
    "# Write the lemmas list to the JSON file\n",
    "with open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
    "    json.dump(generated_pseudoword, outfile, ensure_ascii=False, indent=2)\n",
    "\n",
    "print()\n",
    "time = time.time() - start_time\n",
    "\n",
    "print(f\"{len(generated_pseudoword)} pseudo words successfully generated and loaded in {time//60:.0f}:{(time%60):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b377f7f-3e6c-4b72-8775-0a1aa80adb60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
