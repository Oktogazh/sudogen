{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b066e4bb-7a53-4b7f-a9a8-811c9d6aeef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'w': 'ar', 'r': 42}, {'w': 'bern', 'r': 55}, {'w': 'laouen', 'r': 100}, {'w': \"c'hoarvezout\", 'r': 100}, {'w': 'letern', 'r': 100}, {'w': 'enaou', 'r': 100}, {'w': 'demat', 'r': 100}, {'w': 'ene', 'r': 101}, {'w': 'soubenn', 'r': 101}, {'w': 'kraoñ', 'r': 101}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json\n",
    "from typing import Dict, Tuple, Optional\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import threading\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "\n",
    "locale = \"br\"\n",
    "\n",
    "# Define the file path\n",
    "file_path = f\"{locale}-items.json\"\n",
    "\n",
    "# Write the lemmas list to the JSON file\n",
    "try:\n",
    "    with open(file_path) as f:\n",
    "        content = f.read()\n",
    "        if not content.strip():\n",
    "            raise ValueError(\"The JSON file is empty.\")\n",
    "        items = json.loads(content)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {file_path}\")\n",
    "    items = []\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    items = []\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error: Invalid JSON content in {file_path}\")\n",
    "    items = []\n",
    "\n",
    "print(items[\"keys\"][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b48cb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average rating: 824.63\n"
     ]
    }
   ],
   "source": [
    "# Calculate average rating\n",
    "def calculate_average_rating(items: Dict) -> float:\n",
    "    total_rating = 0\n",
    "    count = 0\n",
    "\n",
    "    for item in items:\n",
    "        if \"r\" in item:  # Check if item has a rating\n",
    "            total_rating += item[\"r\"]\n",
    "            count += 1\n",
    "\n",
    "    avr = total_rating / count if count > 0 else 0\n",
    "\n",
    "    print(f\"\\nAverage rating: {avr:.2f}\")\n",
    "    return avr\n",
    "\n",
    "avr = calculate_average_rating(items[\"keys\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2067fa7c-635f-48a0-89f0-ddbd9b1be71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing items:   0%|                                                                                                                | 0/62169 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing items: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 62169/62169 [00:00<00:00, 1068504.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average rating: 856.84\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from math import floor\n",
    "\n",
    "new_keys = []\n",
    "for item in tqdm(items[\"keys\"], desc=\"Processing items\"):\n",
    "    if item[\"r\"] > 530 and item[\"r\"] < 600:\n",
    "        new_keys.append(\n",
    "            {\"w\": item[\"w\"], \"r\": floor(560 + random.randint(-30, 40))}\n",
    "        )\n",
    "    else:\n",
    "        new_keys.append(item)\n",
    "\n",
    "calculate_average_rating(new_keys)\n",
    "# order the items by rating\n",
    "new_keys.sort(key=lambda x: x[\"r\"])\n",
    "items[\"keys\"] = new_keys\n",
    "\n",
    "# Write the updated items back to the JSON file\n",
    "with open(file_path, \"w\") as f:\n",
    "    json.dump(items, f, indent=0, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b8feffc-0c89-4473-8faf-7cdecc46257f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping entries: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 62494/62494 [3:19:09<00:00,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping complete. Found 55715 unique entries.\n",
      "Results saved to locales/br/ratings.json\n",
      "\n",
      "Statistics:\n",
      "Total unique entries: 55715\n",
      "Rating 1: 6867 entries\n",
      "Rating 2: 47740 entries\n",
      "Rating 3: 1108 entries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Asynchronously fetch all entries in Meurgorf to get their frequency rating (1,2,3)\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json\n",
    "from typing import Dict, Tuple, Optional\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import threading\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "def create_session() -> requests.Session:\n",
    "    \"\"\"Create a requests session with retry strategy and connection pooling.\"\"\"\n",
    "    session = requests.Session()\n",
    "    \n",
    "    # Configure retry strategy\n",
    "    retry_strategy = Retry(\n",
    "        total=3,\n",
    "        backoff_factor=1,\n",
    "        status_forcelist=[429, 500, 502, 503, 504],\n",
    "    )\n",
    "    \n",
    "    adapter = HTTPAdapter(max_retries=retry_strategy, pool_connections=10, pool_maxsize=10)\n",
    "    session.mount(\"http://\", adapter)\n",
    "    session.mount(\"https://\", adapter)\n",
    "    \n",
    "    return session\n",
    "\n",
    "def scrape_single_entry(n: int, session: requests.Session) -> Optional[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Scrape a single entry from the Breton dictionary.\n",
    "    \n",
    "    Args:\n",
    "        n: Entry number to scrape\n",
    "        session: Requests session to use\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (entry_name, rating) or None if failed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Construct the URL for the current entry\n",
    "        url = f\"https://niverel.brezhoneg.bzh/br/meurgorf/{n}\"\n",
    "        \n",
    "        # Make the HTTP request\n",
    "        response = session.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Find the rating element with class 'rating'\n",
    "        rating_element = soup.find(class_='rating')\n",
    "        if not rating_element:\n",
    "            return None\n",
    "        \n",
    "        # Get the data-rating attribute\n",
    "        rating = rating_element.get('data-rating')\n",
    "        if not rating:\n",
    "            return None\n",
    "        \n",
    "        # Convert rating to integer\n",
    "        try:\n",
    "            rating = int(rating)\n",
    "        except ValueError:\n",
    "            return None\n",
    "        \n",
    "        # Get the title element from the head\n",
    "        title_element = soup.find('title')\n",
    "        if not title_element:\n",
    "            return None\n",
    "        \n",
    "        # Extract the entry name from the title\n",
    "        title_text = title_element.get_text()\n",
    "        suffix = \" −\"\n",
    "        \n",
    "        if suffix in title_text:\n",
    "            entry = title_text.split(suffix)[0].strip()\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "        return (entry, rating)\n",
    "        \n",
    "    except requests.RequestException:\n",
    "        return None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def scrape_breton_dictionary_ratings(max_workers: int = 20) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Scrapes the Breton dictionary website to collect entries and their ratings using multi-threading.\n",
    "    \n",
    "    Args:\n",
    "        max_workers: Maximum number of concurrent threads\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, int]: Dictionary mapping entry names to their lowest ratings (1-3)\n",
    "    \"\"\"\n",
    "    dictionary_ratings = {}\n",
    "    lock = threading.Lock()\n",
    "    \n",
    "    # Create a list of all entry numbers\n",
    "    entry_numbers = list(range(1, 62495))\n",
    "    \n",
    "    # Create a progress bar\n",
    "    with tqdm(total=len(entry_numbers), desc=\"Scraping entries\") as pbar:\n",
    "        # Use ThreadPoolExecutor for concurrent requests\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            # Create a session for each worker thread\n",
    "            sessions = {i: create_session() for i in range(max_workers)}\n",
    "            \n",
    "            # Submit all tasks\n",
    "            future_to_entry = {}\n",
    "            session_counter = 0\n",
    "            \n",
    "            for entry_num in entry_numbers:\n",
    "                session = sessions[session_counter % max_workers]\n",
    "                future = executor.submit(scrape_single_entry, entry_num, session)\n",
    "                future_to_entry[future] = entry_num\n",
    "                session_counter += 1\n",
    "            \n",
    "            # Process completed tasks\n",
    "            for future in as_completed(future_to_entry):\n",
    "                entry_num = future_to_entry[future]\n",
    "                \n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    if result:\n",
    "                        entry, rating = result\n",
    "                        \n",
    "                        # Thread-safe dictionary update\n",
    "                        with lock:\n",
    "                            if entry in dictionary_ratings:\n",
    "                                # If current rating is lower (better) than stored rating, update it\n",
    "                                if rating > dictionary_ratings[entry]:\n",
    "                                    dictionary_ratings[entry] = rating\n",
    "                            else:\n",
    "                                # Add new entry to dictionary\n",
    "                                dictionary_ratings[entry] = rating\n",
    "                                \n",
    "                except Exception as exc:\n",
    "                    pass  # Silently ignore errors for cleaner output\n",
    "                \n",
    "                pbar.update(1)\n",
    "            \n",
    "            # Close all sessions\n",
    "            for session in sessions.values():\n",
    "                session.close()\n",
    "    \n",
    "    print(f\"Scraping complete. Found {len(dictionary_ratings)} unique entries.\")\n",
    "    return dictionary_ratings\n",
    "\n",
    "def save_ratings_to_file(entries: Dict[str, int], locale: str = \"br\"):\n",
    "    \"\"\"Save the ratings dictionary to a JSON file.\"\"\"\n",
    "    output_file_path = f\"locales/{locale}/ratings.json\"\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    import os\n",
    "    os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "    \n",
    "    with open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(entries, outfile, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"Results saved to {output_file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set locale (you might want to make this configurable)\n",
    "    locale = \"br\"  # Change this as needed\n",
    "    \n",
    "    # Scrape the dictionary with multi-threading\n",
    "    # You can adjust max_workers based on your system and server tolerance\n",
    "    # 20 is a good balance between speed and being respectful to the server\n",
    "    entries = scrape_breton_dictionary_ratings(max_workers=20)\n",
    "    \n",
    "    # Save to file\n",
    "    save_ratings_to_file(entries, locale)\n",
    "    \n",
    "    # Print some statistics\n",
    "    print(f\"\\nStatistics:\")\n",
    "    print(f\"Total unique entries: {len(entries)}\")\n",
    "    \n",
    "    # Count ratings distribution\n",
    "    rating_counts = {}\n",
    "    for rating in entries.values():\n",
    "        rating_counts[rating] = rating_counts.get(rating, 0) + 1\n",
    "    \n",
    "    for rating in sorted(rating_counts.keys()):\n",
    "        print(f\"Rating {rating}: {rating_counts[rating]} entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7814f0e6-4240-404f-9dc8-f2271f147655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62169\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tems' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     item_rating = \u001b[43mentries\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mkeys\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mw\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m item_rating != \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m item_rating != \u001b[32m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m item_rating != \u001b[32m3\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: 'gaiez'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     43\u001b[39m             in_devri_not_in_MG += \u001b[32m1\u001b[39m\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[43mtems\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mkeys\u001b[39m\u001b[33m\"\u001b[39m][i][\u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     47\u001b[39m         items[\u001b[33m\"\u001b[39m\u001b[33mkeys\u001b[39m\u001b[33m\"\u001b[39m][i][\u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m] += \u001b[32m200\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28mprint\u001b[39m(in_devri_not_in_MG)\n",
      "\u001b[31mNameError\u001b[39m: name 'tems' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the file path\n",
    "file_path = f\"ratings.json\"\n",
    "\n",
    "# Write the lemmas list to the JSON file\n",
    "try:\n",
    "    with open(file_path) as f:\n",
    "        content = f.read()\n",
    "        if not content.strip():\n",
    "            raise ValueError(\"The JSON file is empty.\")\n",
    "        entries = json.loads(content)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {file_path}\")\n",
    "    items = []\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    items = []\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error: Invalid JSON content in {file_path}\")\n",
    "    items = []\n",
    "\n",
    "print(len(items[\"keys\"]))\n",
    "\n",
    "in_devri_not_in_MG = 0\n",
    "for i in range(len(items['keys'])):\n",
    "    try:\n",
    "        item_rating = entries[items[\"keys\"][i][\"w\"]]\n",
    "        if item_rating != 1 and item_rating != 2 and item_rating != 3:\n",
    "            print(item_rating)\n",
    "        if item_rating != None:\n",
    "            if item_rating == 1:\n",
    "                # if word is rare, increase the rating a lot\n",
    "                items[\"keys\"][i][\"r\"] -= 0\n",
    "            elif item_rating == 2:\n",
    "                # if word is rare, increase the rating a little\n",
    "                items[\"keys\"][i][\"r\"] -= 200\n",
    "            elif items[\"keys\"][i][\"r\"] < 500:\n",
    "                # if word is really frequent, decrease its rating\n",
    "                items[\"keys\"][i][\"r\"] -= 0\n",
    "            else:\n",
    "                items[\"keys\"][i][\"r\"] += 0\n",
    "        else:\n",
    "            in_devri_not_in_MG += 1\n",
    "                \n",
    "    except:\n",
    "        print(items[\"keys\"][i][\"w\"])\n",
    "        items[\"keys\"][i]['r'] += 200\n",
    "print(in_devri_not_in_MG)\n",
    "        \n",
    "print(items[\"keys\"][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3565a830-f082-4374-9296-bb473583c84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to locales/br/br-items.json\n"
     ]
    }
   ],
   "source": [
    "def save_updated_ratings(entries: Dict[str, int], locale: str = \"br\"):\n",
    "    \"\"\"Save the ratings dictionary to a JSON file.\"\"\"\n",
    "    output_file_path = f\"locales/{locale}/{locale}-items.json\"\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    import os\n",
    "    os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "    \n",
    "    with open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(entries, outfile, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"Results saved to {output_file_path}\")\n",
    "\n",
    "save_updated_ratings(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228d4f69-8af2-4055-be60-90c35eb65298",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
