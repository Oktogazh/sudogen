{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b066e4bb-7a53-4b7f-a9a8-811c9d6aeef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'w': 'ar', 'r': 552}, {'w': 'bern', 'r': 569}, {'w': 'roeñvaoueg', 'r': 576}, {'w': 'friad', 'r': 584}, {'w': 'lavnenn', 'r': 586}, {'w': 'e-tal-kein', 'r': 591}, {'w': 'strantal', 'r': 591}, {'w': 'fichellad', 'r': 593}, {'w': 'breugeusus', 'r': 596}, {'w': 'arestiñ', 'r': 596}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "locale = \"br\"\n",
    "\n",
    "# Define the file path\n",
    "file_path = f\"locales/{locale}/{locale}-items.json\"\n",
    "\n",
    "# Write the lemmas list to the JSON file\n",
    "try:\n",
    "    with open(file_path) as f:\n",
    "        content = f.read()\n",
    "        if not content.strip():\n",
    "            raise ValueError(\"The JSON file is empty.\")\n",
    "        items = json.loads(content)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {file_path}\")\n",
    "    items = []\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    items = []\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error: Invalid JSON content in {file_path}\")\n",
    "    items = []\n",
    "\n",
    "print(items[\"keys\"][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b8feffc-0c89-4473-8faf-7cdecc46257f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping entries: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 62494/62494 [3:19:09<00:00,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping complete. Found 55715 unique entries.\n",
      "Results saved to locales/br/ratings.json\n",
      "\n",
      "Statistics:\n",
      "Total unique entries: 55715\n",
      "Rating 1: 6867 entries\n",
      "Rating 2: 47740 entries\n",
      "Rating 3: 1108 entries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json\n",
    "from typing import Dict, Tuple, Optional\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import threading\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "def create_session() -> requests.Session:\n",
    "    \"\"\"Create a requests session with retry strategy and connection pooling.\"\"\"\n",
    "    session = requests.Session()\n",
    "    \n",
    "    # Configure retry strategy\n",
    "    retry_strategy = Retry(\n",
    "        total=3,\n",
    "        backoff_factor=1,\n",
    "        status_forcelist=[429, 500, 502, 503, 504],\n",
    "    )\n",
    "    \n",
    "    adapter = HTTPAdapter(max_retries=retry_strategy, pool_connections=10, pool_maxsize=10)\n",
    "    session.mount(\"http://\", adapter)\n",
    "    session.mount(\"https://\", adapter)\n",
    "    \n",
    "    return session\n",
    "\n",
    "def scrape_single_entry(n: int, session: requests.Session) -> Optional[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Scrape a single entry from the Breton dictionary.\n",
    "    \n",
    "    Args:\n",
    "        n: Entry number to scrape\n",
    "        session: Requests session to use\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (entry_name, rating) or None if failed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Construct the URL for the current entry\n",
    "        url = f\"https://niverel.brezhoneg.bzh/br/meurgorf/{n}\"\n",
    "        \n",
    "        # Make the HTTP request\n",
    "        response = session.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Find the rating element with class 'rating'\n",
    "        rating_element = soup.find(class_='rating')\n",
    "        if not rating_element:\n",
    "            return None\n",
    "        \n",
    "        # Get the data-rating attribute\n",
    "        rating = rating_element.get('data-rating')\n",
    "        if not rating:\n",
    "            return None\n",
    "        \n",
    "        # Convert rating to integer\n",
    "        try:\n",
    "            rating = int(rating)\n",
    "        except ValueError:\n",
    "            return None\n",
    "        \n",
    "        # Get the title element from the head\n",
    "        title_element = soup.find('title')\n",
    "        if not title_element:\n",
    "            return None\n",
    "        \n",
    "        # Extract the entry name from the title\n",
    "        title_text = title_element.get_text()\n",
    "        suffix = \" −\"\n",
    "        \n",
    "        if suffix in title_text:\n",
    "            entry = title_text.split(suffix)[0].strip()\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "        return (entry, rating)\n",
    "        \n",
    "    except requests.RequestException:\n",
    "        return None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def scrape_breton_dictionary_ratings(max_workers: int = 20) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Scrapes the Breton dictionary website to collect entries and their ratings using multi-threading.\n",
    "    \n",
    "    Args:\n",
    "        max_workers: Maximum number of concurrent threads\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, int]: Dictionary mapping entry names to their lowest ratings (1-3)\n",
    "    \"\"\"\n",
    "    dictionary_ratings = {}\n",
    "    lock = threading.Lock()\n",
    "    \n",
    "    # Create a list of all entry numbers\n",
    "    entry_numbers = list(range(1, 62495))\n",
    "    \n",
    "    # Create a progress bar\n",
    "    with tqdm(total=len(entry_numbers), desc=\"Scraping entries\") as pbar:\n",
    "        # Use ThreadPoolExecutor for concurrent requests\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            # Create a session for each worker thread\n",
    "            sessions = {i: create_session() for i in range(max_workers)}\n",
    "            \n",
    "            # Submit all tasks\n",
    "            future_to_entry = {}\n",
    "            session_counter = 0\n",
    "            \n",
    "            for entry_num in entry_numbers:\n",
    "                session = sessions[session_counter % max_workers]\n",
    "                future = executor.submit(scrape_single_entry, entry_num, session)\n",
    "                future_to_entry[future] = entry_num\n",
    "                session_counter += 1\n",
    "            \n",
    "            # Process completed tasks\n",
    "            for future in as_completed(future_to_entry):\n",
    "                entry_num = future_to_entry[future]\n",
    "                \n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    if result:\n",
    "                        entry, rating = result\n",
    "                        \n",
    "                        # Thread-safe dictionary update\n",
    "                        with lock:\n",
    "                            if entry in dictionary_ratings:\n",
    "                                # If current rating is lower (better) than stored rating, update it\n",
    "                                if rating > dictionary_ratings[entry]:\n",
    "                                    dictionary_ratings[entry] = rating\n",
    "                            else:\n",
    "                                # Add new entry to dictionary\n",
    "                                dictionary_ratings[entry] = rating\n",
    "                                \n",
    "                except Exception as exc:\n",
    "                    pass  # Silently ignore errors for cleaner output\n",
    "                \n",
    "                pbar.update(1)\n",
    "            \n",
    "            # Close all sessions\n",
    "            for session in sessions.values():\n",
    "                session.close()\n",
    "    \n",
    "    print(f\"Scraping complete. Found {len(dictionary_ratings)} unique entries.\")\n",
    "    return dictionary_ratings\n",
    "\n",
    "def save_ratings_to_file(entries: Dict[str, int], locale: str = \"br\"):\n",
    "    \"\"\"Save the ratings dictionary to a JSON file.\"\"\"\n",
    "    output_file_path = f\"locales/{locale}/ratings.json\"\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    import os\n",
    "    os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "    \n",
    "    with open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(entries, outfile, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"Results saved to {output_file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set locale (you might want to make this configurable)\n",
    "    locale = \"br\"  # Change this as needed\n",
    "    \n",
    "    # Scrape the dictionary with multi-threading\n",
    "    # You can adjust max_workers based on your system and server tolerance\n",
    "    # 20 is a good balance between speed and being respectful to the server\n",
    "    entries = scrape_breton_dictionary_ratings(max_workers=20)\n",
    "    \n",
    "    # Save to file\n",
    "    save_ratings_to_file(entries, locale)\n",
    "    \n",
    "    # Print some statistics\n",
    "    print(f\"\\nStatistics:\")\n",
    "    print(f\"Total unique entries: {len(entries)}\")\n",
    "    \n",
    "    # Count ratings distribution\n",
    "    rating_counts = {}\n",
    "    for rating in entries.values():\n",
    "        rating_counts[rating] = rating_counts.get(rating, 0) + 1\n",
    "    \n",
    "    for rating in sorted(rating_counts.keys()):\n",
    "        print(f\"Rating {rating}: {rating_counts[rating]} entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7814f0e6-4240-404f-9dc8-f2271f147655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'w': 'ar', 'r': 52}, {'w': 'bern', 'r': 69}, {'w': 'roeñvaoueg', 'r': 1576}, {'w': 'friad', 'r': 684}, {'w': 'lavnenn', 'r': 686}, {'w': 'e-tal-kein', 'r': 591}, {'w': 'strantal', 'r': 691}, {'w': 'fichellad', 'r': 693}, {'w': 'breugeusus', 'r': 596}, {'w': 'arestiñ', 'r': 696}]\n",
      "[{'w': 'ar', 'r': 52}, {'w': 'bern', 'r': 69}, {'w': 'roeñvaoueg', 'r': 1076}, {'w': 'friad', 'r': 684}, {'w': 'lavnenn', 'r': 686}, {'w': 'e-tal-kein', 'r': 591}, {'w': 'strantal', 'r': 691}, {'w': 'fichellad', 'r': 693}, {'w': 'breugeusus', 'r': 596}, {'w': 'arestiñ', 'r': 696}]\n"
     ]
    }
   ],
   "source": [
    "# Define the file path\n",
    "file_path = f\"locales/{locale}/ratings.json\"\n",
    "\n",
    "# Write the lemmas list to the JSON file\n",
    "try:\n",
    "    with open(file_path) as f:\n",
    "        content = f.read()\n",
    "        if not content.strip():\n",
    "            raise ValueError(\"The JSON file is empty.\")\n",
    "        entries = json.loads(content)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {file_path}\")\n",
    "    items = []\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    items = []\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error: Invalid JSON content in {file_path}\")\n",
    "    items = []\n",
    "\n",
    "print(items[\"keys\"][:10])\n",
    "print()\n",
    "\n",
    "for i in range(len(items['keys'])):\n",
    "    try:\n",
    "        item_rating = entries[items[\"keys\"][i][\"w\"]]\n",
    "        if item_rating != None:\n",
    "            if item_rating == 1:\n",
    "                # if word is rare, increase the rating a lot\n",
    "                items[\"keys\"][i][\"r\"] -= 500\n",
    "            elif item_rating == 2:\n",
    "                # if word is rare, increase the rating a little\n",
    "                items[\"keys\"][i][\"r\"] -= 0\n",
    "            elif items[\"keys\"][i][\"r\"] < 500:\n",
    "                # if word is really frequent, decrease its rating\n",
    "                items[\"keys\"][i][\"r\"] -= 500\n",
    "            else:\n",
    "                items[\"keys\"][i][\"r\"] = 0\n",
    "                \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "        \n",
    "print(items[\"keys\"][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3565a830-f082-4374-9296-bb473583c84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to locales/br/br-items.json\n"
     ]
    }
   ],
   "source": [
    "def save_updated_ratings(entries: Dict[str, int], locale: str = \"br\"):\n",
    "    \"\"\"Save the ratings dictionary to a JSON file.\"\"\"\n",
    "    output_file_path = f\"locales/{locale}/{locale}-items.json\"\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    import os\n",
    "    os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "    \n",
    "    with open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(entries, outfile, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"Results saved to {output_file_path}\")\n",
    "\n",
    "save_updated_ratings(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228d4f69-8af2-4055-be60-90c35eb65298",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
